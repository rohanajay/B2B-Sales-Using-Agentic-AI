{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEvuPKsw/0/34QaqsFKke4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chhaya-Tundwal05/pg-sales-agent/blob/sample_agent_yash/PG_Sales_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sales AI agent which takes Meeting Transcription as Input and creates summary and next steps**"
      ],
      "metadata": {
        "id": "RfobHEK4YQns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_predictionguard import PredictionGuard  # Corrected import\n",
        "\n",
        "# Set your Prediction Guard API key as an environmental variable\n",
        "os.environ[\"PREDICTIONGUARD_API_KEY\"] = \"xyz\"\n",
        "\n",
        "# Initialize Prediction Guard LLM (corrected)\n",
        "#llm = PredictionGuard(model=\"Hermes-2-Pro-Llama-3-8B\")  # Choose the correct model\n",
        "llm = PredictionGuard(\n",
        "    model= \"Hermes-3-Llama-3.1-70B\",\n",
        "    predictionguard_api_key=os.environ[\"PREDICTIONGUARD_API_KEY\"],\n",
        "    temperature=0.75,\n",
        "    max_tokens=100,\n",
        "    stop=[\"000\"]  # Stop generation at \"000\" or double newlines\n",
        ")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"Dataset_with_Flowing_Conversations.csv\")\n",
        "\n",
        "# Define a prompt template for summarization (fixed variable mismatch)\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"notes\"],  # Corrected to match the placeholder\n",
        "    template=\"Summarize the following meeting notes in 2-3 sentences, focusing on key points, decisions, and action items:\\n\\n{notes}\"\n",
        ")\n",
        "\n",
        "# Create a summarization chain\n",
        "summarization_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "# Function to summarize notes using LangChain and Prediction Guard\n",
        "def summarize_notes(notes):\n",
        "    try:\n",
        "        if not isinstance(notes, str) or notes.strip() == \"\":\n",
        "            return \"No valid notes available.\"\n",
        "\n",
        "        summary = summarization_chain.run({\"notes\": notes})  # Fixed function call\n",
        "        return summary.strip() if summary else \"Summarization failed.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Apply summarization to the dataset\n",
        "df[\"Summary\"] = df[\"Meeting Notes\"].apply(summarize_notes)\n",
        "\n",
        "# Save the updated dataset\n",
        "df.to_csv(\"summarized_leads.csv\", index=False)\n",
        "\n",
        "# Print a sample of the summarized data\n",
        "print(df[[\"Name\", \"Company\", \"Summary\"]].head())\n",
        "\n",
        "# Function to deduce next steps based on summarized notes\n",
        "def deduce_next_steps(row):\n",
        "    summary = row[\"Summary\"]\n",
        "    if \"interested\" in summary.lower() and \"budget\" in summary.lower():\n",
        "        return \"Schedule a follow-up meeting to discuss pricing and contract details.\"\n",
        "    elif \"proposal\" in summary.lower():\n",
        "        return \"Send a detailed proposal and schedule a call to address questions.\"\n",
        "    elif \"demo\" in summary.lower():\n",
        "        return \"Arrange a product demo and provide additional use cases.\"\n",
        "    else:\n",
        "        return \"Send a follow-up email with additional information and case studies.\"\n",
        "\n",
        "# Apply next steps\n",
        "df[\"Next Steps\"] = df.apply(deduce_next_steps, axis=1)\n",
        "import os\n",
        "import pandas as pd\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_predictionguard import PredictionGuard  # Corrected import\n",
        "\n",
        "# Set your Prediction Guard API key as an environmental variable\n",
        "os.environ[\"PREDICTIONGUARD_API_KEY\"] = \"xyz\"\n",
        "\n",
        "# Initialize Prediction Guard LLM (corrected)\n",
        "\n",
        "                  Name                        Company  \\\n",
        "0         Allison Hill                     Taylor Inc\n",
        "1          Carla Kelly         Adams, Zuniga and Wong\n",
        "2    Patricia Peterson                  Graham-Chavez\n",
        "3       Cindy Anderson  Johnston, Sanchez and Kennedy\n",
        "4  Dr. Tracy House DVM                  Russell Group\n",
        "\n",
        "                                             Summary\n",
        "0  The engineer inquired about integrating Predic...\n",
        "1  The CEO of an organization is looking for a sc...\n",
        "2  The CIO inquired about Prediction Guard's comp...\n",
        "3  The CIO inquired about Prediction Guard's comp...\n",
        "4  - Lead shares details about their data infrast...\n",
        "\n",
        "\n",
        "# Save the final dataset\n",
        "df.to_csv(\"final_leads.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI7QQhBHEscY",
        "outputId": "382cf4a3-bf3b-4eb5-daf5-f2d468936428"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Name                        Company  \\\n",
            "0         Allison Hill                     Taylor Inc   \n",
            "1          Carla Kelly         Adams, Zuniga and Wong   \n",
            "2    Patricia Peterson                  Graham-Chavez   \n",
            "3       Cindy Anderson  Johnston, Sanchez and Kennedy   \n",
            "4  Dr. Tracy House DVM                  Russell Group   \n",
            "\n",
            "                                             Summary  \n",
            "0  The engineer inquired about integrating Predic...  \n",
            "1  The CEO of an organization is looking for a sc...  \n",
            "2  The CIO inquired about Prediction Guard's comp...  \n",
            "3  The CIO inquired about Prediction Guard's comp...  \n",
            "4  - Lead shares details about their data infrast...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LOXYrmF3YNa_"
      }
    }
  ]
}